{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Decomposition\n",
    "\n",
    "The goal of this material is to introduce basic time series decomposition methods that can be applied to separate the various sub-patterns that are typically combined within time series data.  Many techniques can be used for this purpose and, as an introduction to this general topic, the computations contained herein are aimed, first, at communicating clearly what time series decompositon is and a general approach.\n",
    "\n",
    "We have seen this image in class previously which nicely visualizes what we will be doing in the two examples included in this Jupyter notebook.\n",
    "\n",
    "![Cleveland Time Series Decomposition](ClevelandTimeSeriesDecomposition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand Pattern Decomposition\n",
    "\n",
    "This first example is obviously fictious data because its patterns appear to be significantly more consistent across time than  real-world data.  Nonetheless, it is a good first exercise, particualrly, because the easily observed patterns make this first exercise easier than is normally the case.\n",
    "\n",
    "This data was adapted from the textbook _Supply Chain Management: 3rd Edition_, by Sunil Chopra and Peter Meindl,  Prentice Hall, 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import all the packages we will need, as well as the magic command for plotting in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TSDataP1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a column for the Quarter index to use with computation, so let's create that now.  We will use a zero-based index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data, first, to begin to understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index,df.Product1Demand)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe the pattern in this graph?  What \"component patterns\" do you see within the overall graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you should observe an overall (positive) trend  and seasonality.  To perceive the trend, ask what results a linear regression analysis would yield for intercept adn slope.  Perhaps, you will intuit that the trend in this graph is a linear one rather than a nonlinear one.\n",
    "\n",
    "You could, and should ask yourself what is causing those patterns.  You may know the causes from experience if you are familiar with the context or, alternately, you may need to do research to determine the causes.  If you were a consultant, you might well be in the latter position.\n",
    "\n",
    "Our goal now is to decompose these data.  Doing so will enable us to forecast demand into the future because the components are easier to detect and express individually, so that we may exptrapolate them into the future.  We need to assume a functional form for how the components contribute to the overall pattern in order to guide the math that we do.  For our pruposes, we will assume this model, which is called an additive model:\n",
    "\n",
    "- $D$ = Product Demand \n",
    "- $q$ = the index of the quarter\n",
    "- $L$ = The 'level' component of the demand pattern which is a constant value\n",
    "- $T$ = The (linear) trend of the data.  This is the amount that demand increases, on average, from one quarter to the next.  T is also a constant.\n",
    "- $S \\left(q \\right)$ = Seasonality component.  We need to figure out how many quarters there are before the seaonal pattern repeats so that we can determine the seasonality component for each quarter, $q$.\n",
    "- $\\epsilon \\left( q \\right)$ is the portion of demand that we will not be able to fit with $L$, $T \\left(q \\right)$ and $S \\left(q \\right)$.\n",
    "\n",
    "\n",
    "$D\\left(q \\right) = L + T \\left(q \\right) + S \\left(q \\right) + \\epsilon \\left( q \\right)$ \n",
    "\n",
    "We can easily get $L$and $T$ from a linear regression analysis.  We will use a new Python package for this analysis.  Many Python packages can do this analysis well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df.index,df['Product1Demand'])\n",
    "print('intercept =', intercept, '    slope =', slope, '     p_value = ',p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to 'remove' the trend and the level from the original demand pattern to see what pattern remains for use to describe seasonality.  We use the <code>DataFrame.apply()</code> method from pandas for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regress_col(row, intercept, slope):\n",
    "    return float(intercept) + row.Quarter * slope\n",
    "    \n",
    "df['regress'] = df.apply(create_regress_col,args = (intercept,slope),axis = \"columns\")\n",
    "df.style.format({\n",
    "    'Product1Demand': '{:,.0f}'.format,\n",
    "    'regress': '{:,.0f}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the computation below, a column is created in the <code>DataFrame</code> whose name is <code>R1</code>.  The <code>R</code> stands for remainder of the original sales trajectory after the regression 'pattern' has been extracted from the original sales pattern.  We still need to find whatever patterns might exist within the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['R1'] = df['Product1Demand'] - df['regress']\n",
    "df.style.format({\n",
    "    'Product1Demand': '{:,.0f}'.format,\n",
    "    'regress': '{:,.0f}'.format,\n",
    "    'R1': '{:,.0f}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the R1 data column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index,df.R1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a repeated pattern.\n",
    "\n",
    "How many quarters pass before the pattern repeats?\n",
    "\n",
    "When the autocorrelation value for a particular lag is large (close to 1) and positive, it indicates a cyclic pattern with the periodicty of that lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(df.index)/2)):\n",
    "    print('autocorrelation, lag =',i,':',df.R1.autocorr(lag = i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code plots each sequential series of 4 points, where 4 corresponds with the periodicty of the data.  Note how the patterns have similar shapes, which is why the autocorrelation with this lag was nearly 1.  Let's create a graph that demonstrates this by plotting each successive group of four points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfQtr = pd.DataFrame()\n",
    "cycleLen = 4\n",
    "for i in range(int(len(df.index)/cycleLen)):\n",
    "    newData = pd.DataFrame({i:df['R1'].iloc[i*cycleLen:(i+1)*cycleLen]})\n",
    "    newData.index = range(0,len(newData))\n",
    "    dfQtr = pd.concat([dfQtr,newData],axis=1)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfQtr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we average the demand for each of the seasonal quarters, so those averages represent all the curves well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = []\n",
    "for i in range(len(dfQtr.index)):\n",
    "    avg.append(dfQtr.iloc[i].mean())\n",
    "\n",
    "dfQtr = pd.concat([dfQtr,pd.DataFrame({'avg':avg})], axis=1)\n",
    "print(dfQtr)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "c = 180\n",
    "for col in dfQtr.columns.values:\n",
    "    if col == 'avg':\n",
    "        ax.plot(dfQtr[col], c = 'r')\n",
    "    else:\n",
    "        ax.plot(dfQtr[col], c = 'k')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the remainder of the demand pattern look like if we use the average seasonality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calcR2(row):\n",
    "#    return row[3] - row[4]\n",
    "    \n",
    "df['S'] = np.NaN\n",
    "df['error'] = np.NaN\n",
    "df['R2'] = np.NaN\n",
    "df['Forecast'] = np.NaN\n",
    "S = dfQtr['avg'].tolist()\n",
    "for i in df.index:\n",
    "    df.loc[i,'S'] = S[i%cycleLen]\n",
    "\n",
    "df['R2'] = df['R1'] - df['S']\n",
    "df['Forecast'] = df['regress'] + df['S']\n",
    "df['error%'] = 100*abs(df['R2'] / df['Product1Demand'])\n",
    "df.style.format({\n",
    "    'Product1Demand': '{:,.0f}'.format,\n",
    "    'regress': '{:,.0f}'.format,\n",
    "    'R1': '{:,.0f}'.format,\n",
    "    'S': '{:,.0f}'.format,\n",
    "    'R2': '{:,.0f}'.format,\n",
    "    'Forecast':'{:,.0f}'.format,\n",
    "    'error': '{:.4f}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize how our model of demand fits actual product demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(df['Product1Demand'],c='k')\n",
    "ax.plot(df['Forecast'],c='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the remainder, that is, the error of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index,df.R2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.index,df.R2)\n",
    "plt.plot(df.index,df.Product1Demand)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a package that does decomposition in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## United States Monthly Home Sales Time Series Decomposition\n",
    "\n",
    "This data was downloaded form teh Internet (link to be added) and it portrays monthly home sales in the United States on a monthly basis where the data have _not been seasonally adjusted_ as is the case with many data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a similar, but more general model for the Home Sales data.  Specifically, we will use this model:\n",
    "\n",
    "$D\\left(q \\right) = T\\left( q \\right) + C\\left( q \\right) + \\epsilon \\left( q \\right)$\n",
    "\n",
    "where\n",
    "\n",
    "- $D\\left( q \\right)$ = Product Demand in Quarter $q$\n",
    "- $q$ = the index of the quarter\n",
    "- $L$ = The 'level' component of the demand pattern which is a constant value\n",
    "- $T\\left( q \\right)$ = $T$ represents the trend of the data which, in this case, could be nonlinear.  $T\\left( q \\right)$ is the trend value for Quarter $q$.\n",
    "- $C\\left( q \\right)$ = Cyclicality demand component, which plays an analogous role to $S\\left( q \\right)$, except that the pattern repeats after some number of periods which might not be four quarters.\n",
    "- $\\epsilon \\left( q \\right)$ is the portion of demand that we will not be able to fit with $L$, $T \\left(q \\right)$ and $S \\left(q \\right)$.\n",
    "\n",
    "Often, the ultimate goal of decomposing data like these is to forecast demand into the future because the components are easier to detect and express individually: Those components can be exptrapolated into the future and combined to create a forecast.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell of code computes the moving average of each point for a data window centered on each point.  The window size is a variable that can be easily changed, and the average squared error is computed in order to help evaluate which window size is appropriate for the moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sqErr(row):\n",
    "    return (row[1] - row[2])**2\n",
    "    \n",
    "dates = ['2007-08','2007-09','2007-10','2007-11','2007-12','2008-01','2008-02','2008-03','2008-04','2008-05','2008-06','2008-07','2008-08','2008-09','2008-10','2008-11','2008-12','2009-01','2009-02','2009-03','2009-04','2009-05','2009-06','2009-07','2009-08','2009-09','2009-10','2009-11','2009-12','2010-01','2010-02','2010-03','2010-04','2010-05','2010-06','2010-07','2010-08','2010-09','2010-10','2010-11','2010-12','2011-01','2011-02','2011-03','2011-04','2011-05','2011-06','2011-07','2011-08','2011-09','2011-10','2011-11','2011-12','2012-01','2012-02','2012-03','2012-04','2012-05','2012-06','2012-07','2012-08','2012-09','2012-10','2012-11','2012-12','2013-01','2013-02','2013-03','2013-04','2013-05','2013-06','2013-07','2013-08','2013-09','2013-10','2013-11','2013-12','2014-01','2014-02','2014-03','2014-04','2014-05','2014-06','2014-07','2014-08','2014-09','2014-10','2014-11','2014-12','2015-01','2015-02','2015-03','2015-04','2015-05','2015-06','2015-07','2015-08','2015-09','2015-10','2015-11','2015-12','2016-01','2016-02','2016-03','2016-04','2016-05','2016-06','2016-07','2016-08','2016-09','2016-10','2016-11','2016-12','2017-01','2017-02','2017-03','2017-04','2017-05','2017-06','2017-07','2017-08','2017-09','2017-10','2017-11','2017-12','2018-01','2018-02','2018-03','2018-04','2018-05','2018-06','2018-07','2018-08']\n",
    "homeSales = [878,674,807,509,1641,701,1048,886,517,661,594,990,597,946,406,358,557,348,509,782,536,638,686,896,520,734,673,760,740,471,344,527,556,565,551,818,552,622,482,415,494,617,704,516,491,466,558,620,523,522,437,403,659,663,422,812,508,624,701,529,629,655,487,516,560,420,403,642,863,652,655,574,559,493,489,369,460,361,357,455,539,610,530,566,521,455,483,387,572,402,386,869,538,612,655,598,462,506,451,418,512,383,336,452,517,572,577,521,549,560,541,574,584,398,361,542,525,624,659,503,548,457,439,431,375,341,422,578,435,502,530,509,220]\n",
    "\n",
    "dfHS = pd.DataFrame({'YearMonth':dates, 'homeSales':homeSales})\n",
    "dfHS['MovAvg'] = np.NaN\n",
    "dfHS['sqErr'] = np.NaN\n",
    "# Chaging the DataFrame index to DatetimeIndex data type is required for using one of the functions below\n",
    "dfHS.index = pd.DatetimeIndex(pd.date_range(pd.Timestamp(year=2007, month=8, day=31), periods = len(dfHS['homeSales'])))\n",
    "#print(len(data),'\\n',data)\n",
    "\n",
    "window = 40\n",
    "window = window - window % 2\n",
    "for i in range(int(window/2),dfHS.shape[0]-int(window/2)):\n",
    "    dfHS.loc[dfHS.index[i],'MovAvg'] = (0.5*dfHS.iloc[i - int(window/2)]['homeSales'] + dfHS.iloc[i - int(window/2)+1:i + int(window/2)]['homeSales'].sum() + 0.5*dfHS.iloc[i + int(window/2)]['homeSales'])/float(window)\n",
    "dfHS['sqErr'] = dfHS.apply(sqErr,axis='columns')\n",
    "# The moving average cannot be applied to all rows and we need to delete those rows because we cannot use them in the analysis\n",
    "dfHS.dropna(how='any',inplace=True)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHS['MovAvg'],label='Moving Avg.')\n",
    "ax.plot(dfHS['homeSales'],label='Home Sales')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "print('Average Squared Error per Month: ',sum(dfHS['sqErr'])/len(dfHS))\n",
    "print(dfHS)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual Home Sales yet to be explained, $R1$, is computed by subtracting the moving average from the demand time series.  Also, these are included in this code cell:\n",
    "- Computing $R1$ as a percentage of demand ($R1Error$).\n",
    "- The dfHS.style.format command demonstrates how to display pandas DataFrame data in whicever readble format you preer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHS['R1'] = dfHS['homeSales'] - dfHS['MovAvg']\n",
    "dfHS['R1Error'] = abs((dfHS['homeSales'] - dfHS['R1'])/dfHS['homeSales'])\n",
    "dfHS.style.format({\n",
    "    'MovAvg': '{:.1f}'.format,\n",
    "    'sqErr': '{:,.1f}'.format,\n",
    "    'R1': '{:,.1f}'.format,\n",
    "    'R1Error': '{:,.3f}'.format\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below helps us visualize the remaining pattern to be decomposed, $R1$, and it also computes the average resdiual demadn pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHS['R1'])\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "print('Average Residual: ', sum(dfHS['R1'])/len(dfHS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as seasonal demand had a higher autocorrelation when the data were offet by four periods, we need to use autocorrelation analysis to detect whether any cyclical patterns exist and how many periods before they are repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxCorr = 0.0\n",
    "period = np.NaN\n",
    "for i in range(1,37):\n",
    "    corr = dfHS['R1'].autocorr(lag=i)\n",
    "    print('Correlation, lag ',i,'   ',corr)\n",
    "    if corr > maxCorr:\n",
    "        maxCorr = corr\n",
    "        period = i\n",
    "print('period = ',period,'     Maximum Correlation = ',maxCorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below breaks the time series into three components corresonding with each of the three cycles in the data.  Note that the third cycle is partial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleLen = period\n",
    "numCycles = int(len(dfHS)/cycleLen + 0.5)\n",
    "cycles = [dfHS.iloc[range(i*period,min((i+1)*period,len(dfHS)))]['R1'] for i in range(numCycles)]\n",
    "fig,ax = plt.subplots()\n",
    "for i in range(len(cycles)):\n",
    "    ax.plot(cycles[i].values,label='Cycle '+str(i))\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code cell:\n",
    "- Computes the average home sales for each of the periods in the cycle.  that is, it computes $C\\left( q \\right)$\n",
    "- Inserts the appropriate $C\\left( q \\right)$ value into the $C$ column in the DataFrame for each Quarter $q$.\n",
    "- Finally, a plot of the cyclicality component $C\\left( q \\right)$ is plotted with the $R1$ column to see how well the cyclicality component and it match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleLen = period   # see prior cell for computation of cyclicality period\n",
    "avg = []            # a list to store the average demand for each period of the cycle\n",
    "numCycles = int(len(dfHS)/cycleLen + 0.5)\n",
    "for j in range(cycleLen):\n",
    "    if j + (numCycles-1) * cycleLen < len(dfHS):\n",
    "        d = dfHS.iloc[range(j,j + (numCycles-1) * cycleLen+1,cycleLen)]['R1']\n",
    "        #print(j,d)\n",
    "        avg.append(sum(d)/len(d))\n",
    "    else:\n",
    "        d = dfHS.iloc[range(j,j + (numCycles-2) * cycleLen+1,cycleLen)]['R1']\n",
    "        #print(j,d)\n",
    "        avg.append(sum(d)/len(d))\n",
    "dfHS['C'] = np.NaN\n",
    "for i in range(len(dfHS)):\n",
    "    dfHS.loc[dfHS.index[i], 'C'] = avg[i % cycleLen]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHS['C'],label='Cyclic Pattern')\n",
    "ax.plot(dfHS['R1'],label='Remainder After Trend')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another view of the cyclical component we've approximated versus each of the three cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in range(len(cycles)):\n",
    "    ax.plot(cycles[i].values,label='Cycle '+str(i),c='k')\n",
    "ax.plot(avg,label='Average Cycle',c='r')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below does these operations:\n",
    "\n",
    "- Computes the remaining residual home sales to be explained, $R2$, after subtracting the cyclical component, $C \\left( q \\right)$. \n",
    "- Computes the remainder after cyclicality, $R2$ as a percentage of the demand time series.\n",
    "- Computes the mathematical model 'fit', composed of the trend and cyclical components: $T\\left( q \\right) + C\\left( q \\right)$.\n",
    "- Plots the fit of the model $T\\left( q \\right) + C\\left( q \\right)$ with the original data, $D \\left( q \\right)$.\n",
    "- Computes the average absolute error of $R2Error$ of the original demand time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHS['R2'] = dfHS['R1'] - dfHS['C']\n",
    "dfHS['R2Error'] = abs(dfHS['R2']/dfHS['homeSales'])\n",
    "dfHS['fit'] = dfHS['MovAvg'] + dfHS['C']\n",
    "print(dfHS)\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHS['homeSales'],label='Home Sales')\n",
    "ax.plot(dfHS['fit'], label = 'Fit')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "print('Average Error: ', sum(dfHS['R2Error'])/len(dfHS))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the residual $R2$ for visualization purposes to observe any remaining patterns that we might want to capture, and also an autocorrelation analysis of the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHS['R2'],label='Remainder after Trend and Cyclical Components')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "maxCorr = 0.0\n",
    "period = np.NaN\n",
    "for i in range(1,37):\n",
    "    corr = dfHS['R2'].autocorr(lag=i)\n",
    "    print('Correlation, lag ',i,'   ',corr)\n",
    "    if corr > maxCorr:\n",
    "        maxCorr = corr\n",
    "        period = i\n",
    "print('period = ',period,'     Maximum Correlation = ',maxCorr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final graph to show the model versus the original data and, as well, the remander $R2$ to judge it relative to the original demand we were trying to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHS['homeSales'],label='Home Sales')\n",
    "ax.plot(dfHS['fit'],label='Fit')\n",
    "ax.plot(dfHS['R2'],label='Residual')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a package that performs time series decomposition in one statement, although you need to do some digging into the results for figure out how the model was constructed.  This is the computation that requires the pandas DataFrame index to be of the DatetimeIndex data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "res = sm.tsa.seasonal_decompose(dfHS['homeSales'],period=36)\n",
    "res.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Approach to Monthly Home Sales Time Series Decomposition\n",
    "\n",
    "The prior approach to decomposing monthly home sales works well, but it is not amenable to a forecast of future sales for the reasons we will discuss in class.  The approach used in this section differs only by how the trend cmoponent is computed, which is a moving average of some number of periods prior to the perio od sales we are trying to forecast.  That is, it uses only data from the past relative to a point to compute the forecast for that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqErr(row):\n",
    "    return (row[1] - row[2])**2\n",
    "    \n",
    "dates = ['2007-08','2007-09','2007-10','2007-11','2007-12','2008-01','2008-02','2008-03','2008-04','2008-05','2008-06','2008-07','2008-08','2008-09','2008-10','2008-11','2008-12','2009-01','2009-02','2009-03','2009-04','2009-05','2009-06','2009-07','2009-08','2009-09','2009-10','2009-11','2009-12','2010-01','2010-02','2010-03','2010-04','2010-05','2010-06','2010-07','2010-08','2010-09','2010-10','2010-11','2010-12','2011-01','2011-02','2011-03','2011-04','2011-05','2011-06','2011-07','2011-08','2011-09','2011-10','2011-11','2011-12','2012-01','2012-02','2012-03','2012-04','2012-05','2012-06','2012-07','2012-08','2012-09','2012-10','2012-11','2012-12','2013-01','2013-02','2013-03','2013-04','2013-05','2013-06','2013-07','2013-08','2013-09','2013-10','2013-11','2013-12','2014-01','2014-02','2014-03','2014-04','2014-05','2014-06','2014-07','2014-08','2014-09','2014-10','2014-11','2014-12','2015-01','2015-02','2015-03','2015-04','2015-05','2015-06','2015-07','2015-08','2015-09','2015-10','2015-11','2015-12','2016-01','2016-02','2016-03','2016-04','2016-05','2016-06','2016-07','2016-08','2016-09','2016-10','2016-11','2016-12','2017-01','2017-02','2017-03','2017-04','2017-05','2017-06','2017-07','2017-08','2017-09','2017-10','2017-11','2017-12','2018-01','2018-02','2018-03','2018-04','2018-05','2018-06','2018-07','2018-08']\n",
    "homeSales = [878,674,807,509,1641,701,1048,886,517,661,594,990,597,946,406,358,557,348,509,782,536,638,686,896,520,734,673,760,740,471,344,527,556,565,551,818,552,622,482,415,494,617,704,516,491,466,558,620,523,522,437,403,659,663,422,812,508,624,701,529,629,655,487,516,560,420,403,642,863,652,655,574,559,493,489,369,460,361,357,455,539,610,530,566,521,455,483,387,572,402,386,869,538,612,655,598,462,506,451,418,512,383,336,452,517,572,577,521,549,560,541,574,584,398,361,542,525,624,659,503,548,457,439,431,375,341,422,578,435,502,530,509,220]\n",
    "\n",
    "dfHSa = pd.DataFrame({'YearMonth':dates, 'homeSales':homeSales})\n",
    "dfHSa['MovAvg'] = np.NaN\n",
    "dfHSa['sqErr'] = np.NaN\n",
    "dfHSa.index = pd.DatetimeIndex(pd.date_range(pd.Timestamp(year=2007, month=8, day=31), periods = len(dfHSa['homeSales'])))\n",
    "#print(len(data),'\\n',data)\n",
    "\n",
    "window = 30\n",
    "for i in range(window+1,len(dfHSa)):\n",
    "    dfHSa.loc[dfHSa.index[i],'MovAvg'] = sum(dfHSa.iloc[range(i-window-1,i)]['homeSales'])/float(window)\n",
    "dfHSa['sqErr'] = dfHSa.apply(sqErr,axis='columns')\n",
    "#print(data.head())\n",
    "dfHSa.dropna(how='any',inplace=True)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHSa['MovAvg'], label='Moving Avg.')\n",
    "ax.plot(dfHSa['homeSales'], label='Home Sales')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()\n",
    "print('Average Squared Error per Month: ',sum(dfHSa['sqErr'])/len(dfHSa))\n",
    "print(dfHSa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHSa['R1'] = dfHSa['homeSales'] - dfHSa['MovAvg']\n",
    "dfHSa['R1Error'] = abs((dfHSa['homeSales'] - dfHSa['R1'])/dfHSa['homeSales'])\n",
    "dfHSa.style.format({\n",
    "    'MovAvg': '{:.1f}'.format,\n",
    "    'sqErr': '{:,.1f}'.format    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHSa['R1'],label='Remainder after Trend')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()\n",
    "print('Average Residual: ', sum(dfHSa['R1'])/len(dfHSa))\n",
    "\n",
    "maxCorr = 0.0\n",
    "period = np.NaN\n",
    "for i in range(1,37):\n",
    "    corr = dfHSa['R1'].autocorr(lag=i)\n",
    "    print('Correlation, lag ',i,'   ',corr)\n",
    "    if corr > maxCorr:\n",
    "        maxCorr = corr\n",
    "        period = i\n",
    "print('period = ',period,'     Maximum Correlation = ',maxCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleLen = period   # see prior cell for computation of cyclicality period\n",
    "avg = []            # a list to store the average demand for each period of the cycle\n",
    "numCycles = int(len(dfHSa)/cycleLen + 0.5)\n",
    "for j in range(cycleLen):\n",
    "    if j + (numCycles-1) * cycleLen < len(dfHSa):\n",
    "        d = dfHSa.iloc[range(j,j + (numCycles-1) * cycleLen+1,cycleLen)]['R1']\n",
    "        print(j,d)\n",
    "        avg.append(sum(d)/len(d))\n",
    "    else:\n",
    "        d = dfHSa.iloc[range(j,j + (numCycles-2) * cycleLen+1,cycleLen)]['R1']\n",
    "        print(j,d)\n",
    "        avg.append(sum(d)/len(d))\n",
    "dfHSa['C'] = np.NaN\n",
    "for i in range(len(dfHSa)):\n",
    "    dfHSa.loc[dfHSa.index[i], 'C'] = avg[i % cycleLen]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHSa['C'],label='Cyclic Pattern')\n",
    "ax.plot(dfHSa['R1'],label='Remainder After Trend')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "for i in range(len(cycles)):\n",
    "    ax.plot(cycles[i].values,label='Cycle '+str(i),c='k')\n",
    "ax.plot(avg,label='Average Cycle',c='r')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfHSa['R2'] = dfHSa['R1'] - dfHSa['C']\n",
    "dfHSa['R2Error'] = abs(dfHSa['R2']/dfHSa['homeSales'])\n",
    "dfHSa['fit'] = dfHSa['MovAvg'] + dfHSa['C']\n",
    "print(dfHSa)\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHSa['homeSales'],label='Home Sales')\n",
    "ax.plot(dfHSa['fit'], label = 'Fit')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()\n",
    "print('Average Error: ', sum(dfHSa['R2Error']/len(dfHSa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHSa['R2'], label='Remainder after Trend and Cyclic Components')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()\n",
    "\n",
    "maxCorr = 0.0\n",
    "period = np.NaN\n",
    "for i in range(1,37):\n",
    "    corr = dfHSa['R2'].autocorr(lag=i)\n",
    "    print('Correlation, lag ',i,'   ',corr)\n",
    "    if corr > maxCorr:\n",
    "        maxCorr = corr\n",
    "        period = i\n",
    "print('period = ',period,'     Maximum Correlation = ',maxCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfHSa['homeSales'],label='Home Sales')\n",
    "ax.plot(dfHSa['fit'],label='Fit')\n",
    "ax.plot(dfHSa['R2'],label='Residual')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Units of Demand')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
